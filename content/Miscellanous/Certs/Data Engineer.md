---
title: "GCP Data Engineering - Round 2!"
date: 2019-06-17T23:53:00+01:00
draft: true
hideLastModified: true
tags: ["gcp", "data engineering"]
---
Its been two years since my last [post](https://www.linkedin.com/pulse/preparation-materials-google-certified-data-engineer-patlolla) on the Professional Data Engineer certification AND it was time for renewal. Successfully renewed the certification exactly 2 years later

I wanted to update some of my recommendations on what I used.

### [Linux Academy](https://linuxacademy.com/cp/modules/view/id/208)

### Google Cloud Documentation for the services - 
[Big Query](https://cloud.google.com/bigquery/), 
[Dataflow](http://cloud.google.com/dataflow/docs), 
[BigTable](https://cloud.google.com/bigtable/docs/), 
[Pub/Sub](https://cloud.google.com/pubsub/docs/overview) , 
[Composer](https://cloud.google.com/composer/docs/concepts/overview)
    and other big data services

### Solution approach
[Migrating Apache Spark to Dataproc](https://cloud.google.com/solutions/migration/hadoop/migrating-apache-spark-jobs-to-cloud-dataproc)

[Building your datalake](https://cloud.google.com/solutions/data-lake/)

[Data Lifecycle](https://cloud-dot-google-developers.appspot.com/solutions/data-lifecycle-cloud-platform)

* When to use Dataflow vs Dataproc, BigTable vs Spanner vs Datastore, ML APIs vs Automl, Composer vs Kubeflow , Transfer Service vs Appliance, Pub/Sub vs Kafka
* IAM Permissions for all the services
* Background - Hadoop and its components


Wishing you the best of luck for your certification